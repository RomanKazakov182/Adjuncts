{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Приложение 1 к курсовой работе \"Семантический парсинг сирконстантов в русском тексте\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Роман Казаков, БКЛ182*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель - создать качественный классификатор русских сирконстантов на основе морфологических и семантических признаков. Ниже будет предложено два подхода к этой цели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируются все необходимые для работы модули."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "KiwHE0-fSoDP",
    "outputId": "c2b35c7c-07d2-4372-d0fa-5dcf51c90f86"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import string\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import category_encoders as ce\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы не загружать на GitHub файл *whole_annotation.json* весом более 600Мб, набор данных для обучения был создан заранее. Поэтому можно не запускать эти функции, а начать сразу с раздела **Модели**.\n",
    "Если всё же есть необходимость скачать корпус, то его можно найти по ссылке: http://nlp.isa.ru/framebank_parser/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция *sircs_analize()* создаёт словарь списков сирконстантов разных классов *main_dict*, в том числе в него входит полный список сирконстантов из файла *framebank_anno_ex_circ.txt*. Сирконстанты, состоящие из предложных групп, обрабатываются в соответствии со схемой, предложенной в конспекте. Для этого предварительно считывается список русских непроизводных предлогов *prep.txt*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYnnG4DqDmCp"
   },
   "outputs": [],
   "source": [
    "def sircs_analize():\n",
    "    with open('prep.txt', encoding='utf-8') as fh:\n",
    "        preps = fh.read()\n",
    "        preps = preps.split('\\n')\n",
    "\n",
    "    with open(\"framebank_anno_ex_circ.txt\", \"r\", encoding='utf8') as fh:\n",
    "        lines = fh.readlines()\n",
    "    del lines[0]\n",
    "\n",
    "    sircs_cat = []\n",
    "    sircs = []\n",
    "    sircs_place = []\n",
    "    sircs_time = []\n",
    "    sircs_manner = []\n",
    "    sircs_degree = []\n",
    "    sircs_purpose = []\n",
    "    sircs_cause = []\n",
    "\n",
    "    for line in lines:\n",
    "        list_par = line.split('\\t')\n",
    "        if list_par[6] == 'Circum':\n",
    "            sirc = list_par[3]\n",
    "            if ' ' in sirc:\n",
    "                sirc = sirc.split(' ')\n",
    "                if (sirc[len(sirc)-2].lower() in preps) and (len(sirc) < 4):\n",
    "                    s_lst = [sirc[len(sirc)-2], sirc[len(sirc)-1]]\n",
    "                    sirc = ' '.join(s_lst)\n",
    "                elif len(sirc) < 3:\n",
    "                    sirc = sirc[len(sirc) - 1]\n",
    "                else:\n",
    "                    continue\n",
    "            for ch in string.punctuation:\n",
    "                sirc = sirc.replace(ch, \"'\")\n",
    "            sirc = sirc.lower()\n",
    "            if (sirc not in sircs) and (len(sirc) > 2):\n",
    "                couple = [sirc, list_par[5]]\n",
    "                sircs_cat.append(tuple(couple))\n",
    "                sircs.append(sirc)\n",
    "                if list_par[5] == ('место' or 'начальная точка' \\\n",
    "                                   or 'конечная точка' or 'расстояние'):\n",
    "                    sircs_place.append(sirc)\n",
    "                time_lst = ['время', 'длительность', 'момент времени', \n",
    "                      'момент времени - конечная точка',\n",
    "                      'время - предел', 'момент времени — предел', \n",
    "                      'длительность - предел', 'время - исходная точка', \n",
    "                      'узуальность']\n",
    "                if list_par[5] in time_lst:\n",
    "                    sircs_time.append(sirc)\n",
    "                if list_par[5] == ('образ действия' or 'звук' or 'способ'):\n",
    "                    sircs_manner.append(sirc)\n",
    "                if list_par[5] == ('степень' or 'предел' or 'интенсивность'):\n",
    "                    sircs_degree.append(sirc)\n",
    "                if list_par[5] == 'цель':\n",
    "                    sircs_purpose.append(sirc)\n",
    "                if list_par[5] == 'причина':\n",
    "                    sircs_cause.append(sirc)\n",
    "\n",
    "    main_dict = {}\n",
    "    main_dict['all'] = sircs\n",
    "    main_dict['place'] = sircs_place\n",
    "    main_dict['time'] = sircs_time\n",
    "    main_dict['manner'] = sircs_manner\n",
    "    main_dict['degree'] = sircs_degree\n",
    "    main_dict['purpose'] = sircs_purpose\n",
    "    main_dict['cause'] = sircs_cause\n",
    "    return main_dict, preps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция *selector(word)* получает на вход словарь с со строкой морфологических и со строкой семантических признаков признаками, она преобразует их в удобный формат словаря, состоящего из 4 пар ключ-значение: **часть речи (*pos*), падеж (*case*), таксономический класс (*t*), лексико-грамматический разряд (*r*)**. В случае отсутствия данных, присваивает *None*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WODPCgw4Dlby"
   },
   "outputs": [],
   "source": [
    "def selector(word):\n",
    "    dict_chars = {}\n",
    "    \n",
    "    if \"feat\" in word:\n",
    "        morpho = word[\"feat\"]\n",
    "        if ' ' in morpho:\n",
    "            lst_morpho = morpho.split()\n",
    "        else:\n",
    "            lst_morpho = [morpho]\n",
    "        pos = ['S', 'A', 'NUM', 'ANUM', 'V', 'ADV', 'PRAEDIC', 'PARENTH', 'SPRO', 'APRO',\n",
    "               'ADVPRO', 'PRAEDICPRO']\n",
    "\n",
    "        saver(dict_chars, lst_morpho, pos, 1, 'pos')\n",
    "\n",
    "        case = ['nom', 'gen', 'dat', 'dat2', 'acc', 'ins', 'loc',\n",
    "                     'gen2', 'acc2', 'loc2', 'voc', 'adnum']\n",
    "        saver(dict_chars, lst_morpho, case, 2, 'case')\n",
    "    else:\n",
    "        dict_chars['pos'] = None\n",
    "        dict_chars['case'] = None\n",
    "\n",
    "    if \"sem\" in word:\n",
    "        sem = word[\"sem\"]\n",
    "        if ' ' in sem:\n",
    "            lst_sem = sem.split()\n",
    "        else:\n",
    "            lst_sem = [sem]\n",
    "        new_lst_sem = []\n",
    "        lst_for_cats = []\n",
    "        for mean in lst_sem:\n",
    "            if ':' in mean:\n",
    "                mean_l = mean.split(':')\n",
    "                if not mean_l[0] in lst_for_cats:\n",
    "                    new_lst_sem.append(tuple([mean_l[0], mean_l[1]]))\n",
    "                    lst_for_cats.append(mean_l[0])\n",
    "        dict_sem = dict(new_lst_sem)\n",
    "        if 't' in dict_sem:\n",
    "            dict_chars['t'] = dict_sem['t']\n",
    "        elif 'pc' in dict_sem:\n",
    "            dict_chars['t'] = dict_sem['pc']\n",
    "        else:\n",
    "            dict_chars['t'] = None\n",
    "        if 'r' in dict_sem:\n",
    "            dict_chars['r'] = dict_sem['r']\n",
    "        else:\n",
    "            dict_chars['r'] = None\n",
    "    else:\n",
    "        dict_chars['t'] = None\n",
    "        dict_chars['r'] = None\n",
    "    return dict_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция *saver(dicti, lst_2, lst_3, num, cat)* - это вспомогательная функция для функции *selector(word)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M7mMNOxRDlz1"
   },
   "outputs": [],
   "source": [
    "def saver(dicti, lst_2, lst_3, num, cat):\n",
    "    for par in lst_2:\n",
    "        if par in lst_3:\n",
    "            dicti[cat] = par\n",
    "            break\n",
    "    if len(dicti) != num:\n",
    "        dicti[cat] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция присваивания метки класса выбоке в соответствии со словарём *main_dict*. Те, что не вошли в у казанные шесть групп, будут в последствии отброшены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ptItOwVA9XgH"
   },
   "outputs": [],
   "source": [
    "def result(token, dict_feat, for_df, main_dict):\n",
    "    if dict_feat['pos'] is not None:\n",
    "        if token in main_dict['place']:\n",
    "            dict_feat['result'] = 1\n",
    "        elif token in main_dict['time']:\n",
    "            dict_feat['result'] = 2\n",
    "        elif token in main_dict['manner']:\n",
    "            dict_feat['result'] = 3\n",
    "        elif token in main_dict['degree']:\n",
    "            dict_feat['result'] = 4\n",
    "        elif token in main_dict['purpose']:\n",
    "            dict_feat['result'] = 5\n",
    "        elif token in main_dict['cause']:\n",
    "            dict_feat['result'] = 6\n",
    "        else:\n",
    "            dict_feat['result'] = 0\n",
    "        if len(dict_feat) == 6:\n",
    "            for_df.append(dict_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь, в *data_for_learning(main_dict, preps)*, происходит обработка примеров из *FrameBank* и создаётся *DataFrame*, в который входит набор данных, который будет использоваться для обучения и тестирования. Итоговый *DataFrame* скачивается в файл *features_with_preps.csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YbyY6xK8s2O"
   },
   "outputs": [],
   "source": [
    "def data_for_learning(main_dict, preps):  \n",
    "    what = input('Введите название файла с корпусом: ')\n",
    "    with open(what, \"r\", encoding='utf8') as read_file:\n",
    "        data = json.load(read_file)\n",
    "    data = list(data.values())\n",
    "    for_df = []\n",
    "    prev_token = '#'\n",
    "    for a in tqdm(data):\n",
    "        for b in a:\n",
    "            for word in b:\n",
    "                token = word[\"form\"].lower()\n",
    "                new = ' '.join([prev_token, token])\n",
    "                if token in preps:\n",
    "                    prev_token = token\n",
    "                    continue\n",
    "                elif token in main_dict['all']:\n",
    "                    prev_token = '#'\n",
    "                    dict_feat = selector(word)\n",
    "                    dict_feat['word'] = token\n",
    "                    result(token, dict_feat, for_df, main_dict)\n",
    "                elif new in main_dict['all']:\n",
    "                    prev_token = '#'\n",
    "                    dict_feat = selector(word)\n",
    "                    dict_feat['word'] = new\n",
    "                    result(new, dict_feat, for_df, main_dict)\n",
    "                else:\n",
    "                    prev_token = '#'\n",
    "    df = pd.DataFrame(for_df, columns=['pos', 'case', 't', 'r', 'result', 'word'])\n",
    "    file_with_preps = 'features_with_preps.csv'\n",
    "    df.to_csv(file_with_preps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь срабатывают все указанные выше функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите название файла с корпусом: whole_annotation.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59861/59861 [05:35<00:00, 178.32it/s]\n"
     ]
    }
   ],
   "source": [
    "adjuncts = sircs_analize()\n",
    "file = data_for_learning(adjuncts[0], adjuncts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Файл распаковывается *features_with_preps.csv* и конвертируется в *DataFrame*. Неизвестные данные объявляются классом *unknown*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TKJXIfxQ8jv4"
   },
   "outputs": [],
   "source": [
    "def reader():\n",
    "    df = pd.read_csv('features_with_preps.csv').dropna(thresh=5)\n",
    "    df = df.fillna('unknown')\n",
    "    df = df.query('result > 0')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Категориальные признаки кодируются **хэш-функцией от ce.Hashing**. Выборка делится на обучающую и тестовую. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_D93gJh_6rm"
   },
   "outputs": [],
   "source": [
    "def prep2(df):\n",
    "    df = df.query('result > 0')\n",
    "    df = df.iloc[:round(df.shape[0]/2), :]\n",
    "    x = df.iloc[:, 1:5]\n",
    "    enc = ce.HashingEncoder(n_components=8)\n",
    "    x = enc.fit_transform(x).to_numpy()\n",
    "    y = df.iloc[:, 5].to_numpy()\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y, \n",
    "                                                        test_size=0.34, random_state=3)\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта функция это шаблон для модели, состоящий из обучения *.fit* и оценки качества модели *metrics.classification_report*. Также измеряется время работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CObSgAGD4Xc3"
   },
   "outputs": [],
   "source": [
    "def model2(model, train_x, train_y, test_x, test_y):\n",
    "    start_time = datetime.now()\n",
    "    model.fit(train_x, train_y)\n",
    "    target_names=['Место', 'Время', 'Образ действия', 'Степень', 'Цель', 'Причина']\n",
    "    report = metrics.classification_report(test_y, model.predict(test_x),\n",
    "                                  target_names=target_names)\n",
    "    print(report)\n",
    "    print('Затраченное время:', datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускается **препроцессинг**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего сирконстантов: 239769\n"
     ]
    }
   ],
   "source": [
    "data2 = prep2(reader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель на осноове ансамлбя (10 штук) классификаторов **SVM** обучается и возвращает результат обучения, кратко проанализированный в тексте работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         Место       0.92      0.73      0.82      4574\n",
      "         Время       0.80      0.82      0.81     16851\n",
      "Образ действия       0.83      0.49      0.61      1252\n",
      "       Степень       0.84      0.85      0.84     14061\n",
      "          Цель       0.79      0.49      0.60        68\n",
      "       Причина       0.64      0.78      0.70      3955\n",
      "\n",
      "      accuracy                           0.81     40761\n",
      "     macro avg       0.80      0.69      0.73     40761\n",
      "  weighted avg       0.81      0.81      0.81     40761\n",
      "\n",
      "Затраченное время: 0:03:02.851928\n"
     ]
    }
   ],
   "source": [
    "mod2 = ensemble.BaggingClassifier(base_estimator=SVC(C=100), n_estimators=10, n_jobs=-1, random_state=3)\n",
    "model2(mod2, data2[0], data2[1], data2[2], data2[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь препроцессинг построен уже на другом методе - на *OneHotEncoder*. Всё остально осталось прежним за исключением того, что кодировщик теперь сохраняется в файл *encoder.pkl*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7acHHl8tAL63"
   },
   "outputs": [],
   "source": [
    "def prep(df):\n",
    "    enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "    enc_df = pd.DataFrame(enc.fit_transform(df[['pos', 'case',\n",
    "                                                't','r']]).toarray())\n",
    "    x = enc_df.to_numpy()\n",
    "    y = df.iloc[:, 5].to_numpy()\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y, \n",
    "                                                        test_size=0.34, random_state=3)\n",
    "    \n",
    "    with open('encoder.pkl', 'wb') as f:\n",
    "        pickle.dump(enc, f)\n",
    "        \n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичный шаблон модели, как в предыдущей модели. Только теперь модель сохраняется в файл *final_model.pkl*. Закомментирован код, с помощью которого можно визуализировать одно из 10 деревьев, которые построит модель. В репозитории уже лежит файл *tree.png*, там и можно найти это самое дерево."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KIwnZBFLAtmd"
   },
   "outputs": [],
   "source": [
    "def model(model, train_x, train_y, test_x, test_y):\n",
    "    start_time = datetime.now()\n",
    "    model.fit(train_x, train_y)\n",
    "    target_names=['Место', 'Время', 'Образ действия', 'Степень', 'Цель', 'Причина']\n",
    "    report = metrics.classification_report(test_y, model.predict(test_x),\n",
    "                                  target_names=target_names)\n",
    "    print(report)\n",
    "    print('Затраченное время:', datetime.now() - start_time)\n",
    "    \n",
    "    with open('final_model.pkl','wb') as f:\n",
    "        pickle.dump(model,f)\n",
    "        \n",
    "#     Нужно для создания визуализации дерева:\n",
    "#     estimator = model.estimators_[5]\n",
    "#     export_graphviz(estimator, \n",
    "#                 out_file='tree.dot', \n",
    "#                 class_names = target_names,\n",
    "#                 rounded = True, proportion = False, \n",
    "#                 precision = 2, filled = True)\n",
    "#     call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "#     Image(filename = 'tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполняется препроцессинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "MFk_35gieVVq",
    "outputId": "a7e11b5f-749a-45a4-d05c-2cded1e6bf0b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего сирконстантов: 264095\n"
     ]
    }
   ],
   "source": [
    "data = prep(reader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь наша модель работает на основе метода **RandomForestClassifier()**, с \"лесом\", состоящим из 10 деревьев. Ещё раз стоит указать, что кросс-валидация не принесла никаких новых успехов в этой модели по сравнению с гиперпараметрами по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YZxGFUlrNgad",
    "outputId": "38d59753-dfa7-40e6-817b-d3eea6f5dc91",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         Место       0.95      0.96      0.96     14261\n",
      "         Время       0.98      0.97      0.98     35183\n",
      "Образ действия       0.93      0.83      0.88      3439\n",
      "       Степень       0.91      0.98      0.95     28224\n",
      "          Цель       0.82      0.74      0.78       328\n",
      "       Причина       1.00      0.81      0.89      8358\n",
      "\n",
      "      accuracy                           0.95     89793\n",
      "     macro avg       0.93      0.88      0.90     89793\n",
      "  weighted avg       0.95      0.95      0.95     89793\n",
      "\n",
      "Затраченное время: 0:00:01.332014\n"
     ]
    }
   ],
   "source": [
    "mod = ensemble.RandomForestClassifier(random_state=3, n_estimators=10, n_jobs=-1)\n",
    "model(mod, data[0], data[1], data[2], data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка значимости каждого из признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без **части речи**. Важно отметить, что здесь нет отдельных функций с прпроцессингом для обучения без одного признака. Чтобы получить результат без признака, нужно удалить его из фильтра колонок в функции *prep(df)* (там, где *.fit_transform*).
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         Место       0.95      0.96      0.96     14261\n",
      "         Время       0.97      0.98      0.97     35183\n",
      "Образ действия       0.93      0.82      0.87      3439\n",
      "       Степень       0.92      0.97      0.94     28224\n",
      "          Цель       0.84      0.73      0.78       328\n",
      "       Причина       0.99      0.81      0.89      8358\n",
      "\n",
      "      accuracy                           0.95     89793\n",
      "     macro avg       0.93      0.88      0.90     89793\n",
      "  weighted avg       0.95      0.95      0.95     89793\n",
      "\n",
      "Затраченное время: 0:00:01.453198\n"
     ]
    }
   ],
   "source": [
    "mod = ensemble.RandomForestClassifier(random_state=3, n_estimators=10, n_jobs=-1)\n",
    "model(mod, data[0], data[1], data[2], data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без **падежа**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         Место       0.94      0.91      0.93     14261\n",
      "         Время       0.93      0.96      0.95     35183\n",
      "Образ действия       0.74      0.77      0.76      3439\n",
      "       Степень       0.90      0.91      0.91     28224\n",
      "          Цель       0.50      0.68      0.58       328\n",
      "       Причина       0.99      0.80      0.89      8358\n",
      "\n",
      "      accuracy                           0.92     89793\n",
      "     macro avg       0.83      0.84      0.83     89793\n",
      "  weighted avg       0.92      0.92      0.92     89793\n",
      "\n",
      "Затраченное время: 0:00:01.223505\n"
     ]
    }
   ],
   "source": [
    "mod = ensemble.RandomForestClassifier(random_state=3, n_estimators=10, n_jobs=-1)\n",
    "model(mod, data[0], data[1], data[2], data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без **таксономического класса**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/romankazakov/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         Место       0.88      0.48      0.62     14261\n",
      "         Время       0.88      0.68      0.77     35183\n",
      "Образ действия       0.67      0.61      0.64      3439\n",
      "       Степень       0.58      0.93      0.71     28224\n",
      "          Цель       0.74      0.34      0.47       328\n",
      "       Причина       1.00      0.71      0.83      8358\n",
      "\n",
      "      accuracy                           0.72     89793\n",
      "     macro avg       0.79      0.62      0.67     89793\n",
      "  weighted avg       0.79      0.72      0.73     89793\n",
      "\n",
      "Затраченное время: 0:00:00.790276\n"
     ]
    }
   ],
   "source": [
    "mod = ensemble.RandomForestClassifier(random_state=3, n_jobs=-1)\n",
    "model(mod, data[0], data[1], data[2], data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без **лексико-грамматического разряда**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/romankazakov/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "         Место       0.92      0.82      0.87     14261\n",
      "         Время       0.93      0.88      0.90     35183\n",
      "Образ действия       0.90      0.79      0.84      3439\n",
      "       Степень       0.84      0.91      0.87     28224\n",
      "          Цель       0.62      0.30      0.40       328\n",
      "       Причина       0.56      0.66      0.61      8358\n",
      "\n",
      "      accuracy                           0.85     89793\n",
      "     macro avg       0.80      0.73      0.75     89793\n",
      "  weighted avg       0.86      0.85      0.86     89793\n",
      "\n",
      "Затраченное время: 0:00:01.229538\n"
     ]
    }
   ],
   "source": [
    "mod = ensemble.RandomForestClassifier(random_state=3, n_jobs=-1)\n",
    "model(mod, data[0], data[1], data[2], data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведена маленькая программа, которая помогает реально использовать работающий классификатор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция *to_cats(number)* просто реконвертирует из метки класса его название."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cats(number):\n",
    "    if number == 0:\n",
    "        return 'Не определено или входит в категорию \"прочее\"'\n",
    "    elif number == 1:\n",
    "        return 'Место'\n",
    "    elif number == 2:\n",
    "        return 'Время'\n",
    "    elif number == 3:\n",
    "        return 'Образ действия'\n",
    "    elif number == 4:\n",
    "        return 'Степень'\n",
    "    elif number == 5:\n",
    "        return 'Цель'\n",
    "    elif number == 6:\n",
    "        return 'Причина'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция *for_use(new_df)* принимает на вход DataFrame с колонками 'word' (слово), 'pos' (часть речи), 'case' (падеж), 't' (тематический класс), 'r' (лексико-грамматический разряд). Неизвестные данные или те, которые невозможно установить, обозначаются как *None*. Кодирование и предсказание делаются по заране заготовленным (сохранённым) моделям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_use(new_df):\n",
    "    with open('encoder.pkl', 'rb') as f:\n",
    "        enc = pickle.load(f)\n",
    "    with open('final_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    new_df = new_df.fillna('unknown')\n",
    "    new_data = pd.DataFrame(enc.transform(new_df[['pos', 'case', 't','r']]).toarray()).to_numpy()\n",
    "    result = model.predict(new_data).tolist()\n",
    "    \n",
    "    for index, row in new_df.iterrows():\n",
    "        print(row['word'], '–--', to_cats(result[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример использования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь на триальном примере можно увидеть, как работает программа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "до дома –-- Место\n",
      "вчера –-- Время\n"
     ]
    }
   ],
   "source": [
    "example = [{'word': 'до дома', 'pos': 'S', 'case': 'gen', 't': 'constr', 'r': 'concr'},\n",
    "          {'word': 'вчера', 'pos': 'ADV', 'case': None, 't':'time', 'r': None}]\n",
    "example_df = pd.DataFrame(example)\n",
    "\n",
    "for_use(example_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Для анализа полученных результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция res() возвращает файл *mistakes.csv* с уникальными ошибками, полученных при прогнозе для всех элементов выборки. Она была нужна, скорее, для того, чтобы описать ошибки в работе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res():    \n",
    "    with open('encoder.pkl', 'rb') as f:\n",
    "        enc = pickle.load(f)\n",
    "    with open('final_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    data = reader()\n",
    "    new_enc_df = pd.DataFrame(enc.transform(data[['pos', 'case',\n",
    "                                                't','r']]).toarray())\n",
    "    x = new_enc_df.to_numpy()\n",
    "    y = data.iloc[:, 5].to_numpy()\n",
    "    counter = 0\n",
    "    counter_mist = 0\n",
    "    mistakes = []\n",
    "    real_predict = zip(data.iloc[:, 5], model.predict(x).tolist())\n",
    "    for control in real_predict:\n",
    "        if control[1] != control[0]:\n",
    "            counter_mist += 1\n",
    "            mist = {}\n",
    "            mist['word'] = data.iloc[counter, 6]\n",
    "            mist['true'] = to_cats(control[0])\n",
    "            mist['prediction'] = to_cats(control[1])\n",
    "            mist['pos'] = data.iloc[counter, 1]\n",
    "            mist['case'] = data.iloc[counter, 2]\n",
    "            mist['t'] = data.iloc[counter, 3]\n",
    "            mist['r'] = data.iloc[counter, 4]\n",
    "            mistakes.append(mist)\n",
    "        counter +=1\n",
    "    print('Всего ошибок:', counter_mist)\n",
    "    df_mistakes = pd.DataFrame(mistakes)\n",
    "    df_mistakes.drop_duplicates(keep=False, \n",
    "                                subset=['word', 'true', 'prediction'],\n",
    "                                inplace=True)\n",
    "    print('Всего уникальных ошибок:', df_mistakes.shape[0]) \n",
    "    df_mistakes.to_csv('mistakes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего сирконстантов: 264095\n",
      "Всего ошибок: 12843\n",
      "Всего уникальных ошибок: 76\n"
     ]
    }
   ],
   "source": [
    "res()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом всё, спасибо за внимание!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Adjuncts.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
